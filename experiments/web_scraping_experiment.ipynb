{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T03:28:51.682790Z",
     "start_time": "2025-06-26T03:28:51.322392Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "\n",
    "def scrape_and_clean(url):\n",
    "    # Fetch webpage content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    html = response.text\n",
    "\n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    # Remove unwanted tags like script and style\n",
    "    for tag in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\", \"aside\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Extract text\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "\n",
    "    # Collapse and clean up whitespace\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # Optionally, you can limit output length\n",
    "    return cleaned  # first 2000 characters\n",
    "\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.intuz.com/blog/building-multi-ai-agent-workflows-with-langchain\"\n",
    "content = scrape_and_clean(url)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2769236d332ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T03:28:37.554944Z",
     "start_time": "2025-06-26T03:28:37.542950Z"
    }
   },
   "outputs": [],
   "source": [
    "content[1995:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc99384f96bfb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T03:30:53.101303Z",
     "start_time": "2025-06-26T03:30:52.494543Z"
    }
   },
   "outputs": [],
   "source": [
    "from markdownify import markdownify as md\n",
    "\n",
    "\n",
    "def scrape_and_convert_to_markdown(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    html = response.text\n",
    "\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    # Optional: remove unwanted tags\n",
    "    for tag in soup([\"script\", \"style\", \"footer\", \"nav\", \"aside\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # You can focus on main content, for example:\n",
    "    main = soup.body  # try soup.find('main') for better results on many sites\n",
    "\n",
    "    if main is not None:\n",
    "        content_html = str(main)\n",
    "    else:\n",
    "        content_html = str(soup)\n",
    "\n",
    "    # Convert HTML to Markdown\n",
    "    markdown = md(content_html)\n",
    "    return markdown\n",
    "\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.intuz.com/blog/building-multi-ai-agent-workflows-with-langchain\"\n",
    "md_content = scrape_and_convert_to_markdown(url)\n",
    "print(md_content)\n",
    "# chunk with unstructured for markdown?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0276b95782d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
